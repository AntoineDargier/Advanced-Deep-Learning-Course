{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlCNZsWlOSfP"
   },
   "source": [
    "# Practical Session on Graph Neural Networks\n",
    "\n",
    "**by Matthieu Nastorg**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0RMEfCaEehI"
   },
   "source": [
    "## **PART 1 : CODING** (8/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5Lp4PasOby4"
   },
   "source": [
    "### Install Pytorch Geometric\n",
    "\n",
    "To handle graph data, we use the library Pytorch Geometric : https://pytorch-geometric.readthedocs.io/en/latest/\n",
    "\n",
    "*   If you use _Google Colab_, simply run the following cell to install Pytorch Geometric (**advised**).\n",
    "*   If you plan using your _own environment_, follow the documentation to install Pytorch Geometric : https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html and skip the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "buW3eZmrj1N2",
    "outputId": "2bc70b0f-7224-41ab-c2ac-18d9adc44adf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
      "Collecting torch-scatter\n",
      "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.0%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (9.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.1.0+pt113cu116\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
      "Collecting torch-sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.16%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-sparse) (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy->torch-sparse) (1.22.4)\n",
      "Installing collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.16+pt113cu116\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
      "Collecting torch-cluster\n",
      "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_cluster-1.6.0%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-cluster) (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy->torch-cluster) (1.22.4)\n",
      "Installing collected packages: torch-cluster\n",
      "Successfully installed torch-cluster-1.6.0+pt113cu116\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
      "Collecting torch-spline-conv\n",
      "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_spline_conv-1.2.1%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (874 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m874.7/874.7 KB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
      "Successfully installed torch-spline-conv-1.2.1+pt113cu116\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (4.65.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.22.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (2.25.1)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.2.1)\n",
      "Collecting psutil>=5.8.0\n",
      "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch-geometric) (2.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (1.26.14)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
      "Building wheels for collected packages: torch-geometric\n",
      "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=629d1d9e8277b33a72ded116e694f7e7649dce6628e48d5f2a0bf0512c461cf2\n",
      "  Stored in directory: /root/.cache/pip/wheels/31/b2/8c/9b4bb72a4384eabd1ffeab2b7ead692c9165e35711f8a9dc72\n",
      "Successfully built torch-geometric\n",
      "Installing collected packages: psutil, torch-geometric\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.4.8\n",
      "    Uninstalling psutil-5.4.8:\n",
      "      Successfully uninstalled psutil-5.4.8\n",
      "Successfully installed psutil-5.9.4 torch-geometric-2.2.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "psutil"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## INSTALL TORCH GEOMETRIC ##################\n",
    "# https://pytorch-geometric.readthedocs.io/en/latest/ \n",
    "#####################################################\n",
    "import torch \n",
    "\n",
    "def format_pytorch_version(version):\n",
    "  return version.split('+')[0]\n",
    "\n",
    "TORCH_version = torch.__version__\n",
    "TORCH = format_pytorch_version(TORCH_version)\n",
    "\n",
    "def format_cuda_version(version):\n",
    "  return 'cu' + version.replace('.', '')\n",
    "\n",
    "CUDA_version = torch.version.cuda\n",
    "CUDA = format_cuda_version(CUDA_version)\n",
    "\n",
    "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04JPKXjDclTj"
   },
   "source": [
    "### Import required packages\n",
    "\n",
    "Run the following cell to import all required packages. This cell **must not** be modified.\n",
    "\n",
    "To significantly accelerate your training, it is advised to use GPU. Using Google Colab, you need to activate it : \n",
    "\n",
    "*   Edit --> Notebook Setting --> Hardware accelerator --> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXGDmBMYgA_x"
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "################## PACKAGES #########################\n",
    "#####################################################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as graphnn\n",
    "from sklearn.metrics import f1_score\n",
    "from torch_geometric.datasets import PPI\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UvCNG8FgdS-"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "We use the Protein-Protein Interaction (PPI) network dataset which includes:\n",
    "- 20 graphs for training \n",
    "- 2 graphs for validation\n",
    "- 2 graphs for testing\n",
    "\n",
    "One graph of the PPI dataset has on average 2372 nodes. Each node:\n",
    "- 50 features : positional gene sets / motif gene / immunological signatures ...\n",
    "- 121 (binary) labels : gene ontology sets (way to classify gene products like proteins).\n",
    "\n",
    "**This problem aims to predict, for a given PPI graph, the correct node's labels**.\n",
    "\n",
    "**It is a node (multi-level) classification task** (trained using supervised learning). \n",
    "\n",
    "For your curiosity, more details information on the dataset and some applications:\n",
    "- https://cs.stanford.edu/~jure/pubs/pathways-psb18.pdf\n",
    "- https://arxiv.org/abs/1707.04638\n",
    "\n",
    "To understand how a graph data is implemented in Pytorch Geometric, refer to : https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IwdNhvzVNkZB",
    "outputId": "5d7cd434-2cee-43b6-bc0a-2c74f92f7430"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://data.dgl.ai/dataset/ppi.zip\n",
      "Extracting ./ppi.zip\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the train dataset:  20\n",
      "Number of samples in the val dataset:  2\n",
      "Number of samples in the test dataset:  2\n",
      "Output of one sample from the train dataset:  Data(x=[1767, 50], edge_index=[2, 32318], y=[1767, 121])\n",
      "Edge_index :\n",
      "tensor([[   0,    0,    0,  ..., 1744, 1745, 1749],\n",
      "        [ 372, 1101,  766,  ..., 1745, 1744, 1739]])\n",
      "Number of features per node:  50\n",
      "Number of classes per node:  121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### LOAD DATASETS\n",
    "\n",
    "BATCH_SIZE = 2 \n",
    "\n",
    "# Train Dataset\n",
    "train_dataset = PPI(root=\"\", split='train')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "# Val Dataset\n",
    "val_dataset = PPI(root=\"\", split='val')\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "# Test Dataset\n",
    "test_dataset = PPI(root=\"\", split='test')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Number of features and classes\n",
    "n_features, n_classes = train_dataset[0].x.shape[1], train_dataset[0].y.shape[1]\n",
    "\n",
    "print(\"Number of samples in the train dataset: \", len(train_dataset))\n",
    "print(\"Number of samples in the val dataset: \", len(test_dataset))\n",
    "print(\"Number of samples in the test dataset: \", len(test_dataset))\n",
    "print(\"Output of one sample from the train dataset: \", train_dataset[0])\n",
    "print(\"Edge_index :\")\n",
    "print(train_dataset[0].edge_index)\n",
    "print(\"Number of features per node: \", n_features)\n",
    "print(\"Number of classes per node: \", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiCcn9qeO6Nm"
   },
   "source": [
    "### Define a basic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RjzEiJ-eVot"
   },
   "source": [
    "Here we define a very simple Graph Neural Network model which will be used as our baseline. This model consists of three graph convolutional layers (from https://arxiv.org/pdf/1609.02907.pdf). The first two layers computes 256 features, followed by an ELU activation function. The last layer is used for (multi-level) classification task, computing 121 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Km-GN1aMpd_"
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "################## MODEL ############################\n",
    "#####################################################\n",
    "class BasicGraphModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.graphconv1 = graphnn.GCNConv(input_size, hidden_size)\n",
    "        self.graphconv2 = graphnn.GCNConv(hidden_size, hidden_size)\n",
    "        self.graphconv3 = graphnn.GCNConv(hidden_size, output_size)\n",
    "\n",
    "        self.elu = nn.ELU()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = self.graphconv1(x, edge_index)\n",
    "        x = self.elu(x)\n",
    "        x = self.graphconv2(x, edge_index)\n",
    "        x = self.elu(x)\n",
    "        x = self.graphconv3(x, edge_index)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ekk0TrOktOB"
   },
   "source": [
    "Next we construct the function to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4lneoadMxqy"
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "############## TRAIN FUNCTION #######################\n",
    "#####################################################\n",
    "def train(model, loss_fcn, device, optimizer, max_epochs, train_dataloader, val_dataloader):\n",
    "\n",
    "    epoch_list = []\n",
    "    scores_list = []\n",
    "\n",
    "    # loop over epochs\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        # loop over batches\n",
    "        for i, train_batch in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            train_batch_device = train_batch.to(device)\n",
    "            # logits is the output of the model\n",
    "            logits = model(train_batch_device.x, train_batch_device.edge_index)\n",
    "            # compute the loss\n",
    "            loss = loss_fcn(logits, train_batch_device.y)\n",
    "            # optimizer step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        loss_data = np.array(losses).mean()\n",
    "        print(\"Epoch {:05d} | Loss: {:.4f}\".format(epoch + 1, loss_data))\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            # evaluate the model on the validation set\n",
    "            # computes the f1-score (see next function)\n",
    "            score = evaluate(model, loss_fcn, device, val_dataloader)\n",
    "            print(\"F1-Score: {:.4f}\".format(score))\n",
    "            scores_list.append(score)\n",
    "            epoch_list.append(epoch)\n",
    "\n",
    "    return epoch_list, scores_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTd9OqaelLni"
   },
   "source": [
    "Next function is designed to evaluate the performance of the model, computing the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PajZzg5zM7V1"
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "############### TEST FUNCTION #######################\n",
    "#####################################################\n",
    "def evaluate(model, loss_fcn, device, dataloader):\n",
    "\n",
    "    score_list_batch = []\n",
    "\n",
    "    model.eval()\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        batch = batch.to(device)\n",
    "        output = model(batch.x, batch.edge_index)\n",
    "        loss_test = loss_fcn(output, batch.y)\n",
    "        predict = np.where(output.detach().cpu().numpy() >= 0, 1, 0)\n",
    "        score = f1_score(batch.y.cpu().numpy(), predict, average=\"micro\")\n",
    "        score_list_batch.append(score)\n",
    "\n",
    "    return np.array(score_list_batch).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EilgopwMlpsu"
   },
   "source": [
    "Let's train this model !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xkqo7e0gNACE",
    "outputId": "ed6cb729-137f-4b21-93da-ee873b7ae6d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Device:  cuda\n",
      "Epoch 00001 | Loss: 0.6380\n",
      "F1-Score: 0.4537\n",
      "Epoch 00002 | Loss: 0.5816\n",
      "Epoch 00003 | Loss: 0.5625\n",
      "Epoch 00004 | Loss: 0.5560\n",
      "Epoch 00005 | Loss: 0.5511\n",
      "Epoch 00006 | Loss: 0.5458\n",
      "F1-Score: 0.4871\n",
      "Epoch 00007 | Loss: 0.5413\n",
      "Epoch 00008 | Loss: 0.5375\n",
      "Epoch 00009 | Loss: 0.5344\n",
      "Epoch 00010 | Loss: 0.5318\n",
      "Epoch 00011 | Loss: 0.5290\n",
      "F1-Score: 0.5273\n",
      "Epoch 00012 | Loss: 0.5263\n",
      "Epoch 00013 | Loss: 0.5238\n",
      "Epoch 00014 | Loss: 0.5213\n",
      "Epoch 00015 | Loss: 0.5191\n",
      "Epoch 00016 | Loss: 0.5169\n",
      "F1-Score: 0.5276\n",
      "Epoch 00017 | Loss: 0.5147\n",
      "Epoch 00018 | Loss: 0.5125\n",
      "Epoch 00019 | Loss: 0.5103\n",
      "Epoch 00020 | Loss: 0.5081\n",
      "Epoch 00021 | Loss: 0.5060\n",
      "F1-Score: 0.5223\n",
      "Epoch 00022 | Loss: 0.5038\n",
      "Epoch 00023 | Loss: 0.5017\n",
      "Epoch 00024 | Loss: 0.4996\n",
      "Epoch 00025 | Loss: 0.4975\n",
      "Epoch 00026 | Loss: 0.4954\n",
      "F1-Score: 0.5284\n",
      "Epoch 00027 | Loss: 0.4935\n",
      "Epoch 00028 | Loss: 0.4915\n",
      "Epoch 00029 | Loss: 0.4897\n",
      "Epoch 00030 | Loss: 0.4879\n",
      "Epoch 00031 | Loss: 0.4863\n",
      "F1-Score: 0.5393\n",
      "Epoch 00032 | Loss: 0.4845\n",
      "Epoch 00033 | Loss: 0.4827\n",
      "Epoch 00034 | Loss: 0.4810\n",
      "Epoch 00035 | Loss: 0.4792\n",
      "Epoch 00036 | Loss: 0.4778\n",
      "F1-Score: 0.5509\n",
      "Epoch 00037 | Loss: 0.4761\n",
      "Epoch 00038 | Loss: 0.4748\n",
      "Epoch 00039 | Loss: 0.4736\n",
      "Epoch 00040 | Loss: 0.4730\n",
      "Epoch 00041 | Loss: 0.4721\n",
      "F1-Score: 0.5679\n",
      "Epoch 00042 | Loss: 0.4721\n",
      "Epoch 00043 | Loss: 0.4706\n",
      "Epoch 00044 | Loss: 0.4695\n",
      "Epoch 00045 | Loss: 0.4669\n",
      "Epoch 00046 | Loss: 0.4655\n",
      "F1-Score: 0.5708\n",
      "Epoch 00047 | Loss: 0.4642\n",
      "Epoch 00048 | Loss: 0.4643\n",
      "Epoch 00049 | Loss: 0.4617\n",
      "Epoch 00050 | Loss: 0.4612\n",
      "Epoch 00051 | Loss: 0.4604\n",
      "F1-Score: 0.5677\n",
      "Epoch 00052 | Loss: 0.4607\n",
      "Epoch 00053 | Loss: 0.4602\n",
      "Epoch 00054 | Loss: 0.4596\n",
      "Epoch 00055 | Loss: 0.4596\n",
      "Epoch 00056 | Loss: 0.4589\n",
      "F1-Score: 0.5896\n",
      "Epoch 00057 | Loss: 0.4574\n",
      "Epoch 00058 | Loss: 0.4567\n",
      "Epoch 00059 | Loss: 0.4543\n",
      "Epoch 00060 | Loss: 0.4532\n",
      "Epoch 00061 | Loss: 0.4512\n",
      "F1-Score: 0.5876\n",
      "Epoch 00062 | Loss: 0.4500\n",
      "Epoch 00063 | Loss: 0.4490\n",
      "Epoch 00064 | Loss: 0.4485\n",
      "Epoch 00065 | Loss: 0.4474\n",
      "Epoch 00066 | Loss: 0.4469\n",
      "F1-Score: 0.6029\n",
      "Epoch 00067 | Loss: 0.4463\n",
      "Epoch 00068 | Loss: 0.4460\n",
      "Epoch 00069 | Loss: 0.4457\n",
      "Epoch 00070 | Loss: 0.4449\n",
      "Epoch 00071 | Loss: 0.4446\n",
      "F1-Score: 0.6009\n",
      "Epoch 00072 | Loss: 0.4452\n",
      "Epoch 00073 | Loss: 0.4433\n",
      "Epoch 00074 | Loss: 0.4434\n",
      "Epoch 00075 | Loss: 0.4424\n",
      "Epoch 00076 | Loss: 0.4408\n",
      "F1-Score: 0.5994\n",
      "Epoch 00077 | Loss: 0.4392\n",
      "Epoch 00078 | Loss: 0.4397\n",
      "Epoch 00079 | Loss: 0.4387\n",
      "Epoch 00080 | Loss: 0.4383\n",
      "Epoch 00081 | Loss: 0.4375\n",
      "F1-Score: 0.6223\n",
      "Epoch 00082 | Loss: 0.4369\n",
      "Epoch 00083 | Loss: 0.4360\n",
      "Epoch 00084 | Loss: 0.4355\n",
      "Epoch 00085 | Loss: 0.4351\n",
      "Epoch 00086 | Loss: 0.4356\n",
      "F1-Score: 0.6067\n",
      "Epoch 00087 | Loss: 0.4348\n",
      "Epoch 00088 | Loss: 0.4345\n",
      "Epoch 00089 | Loss: 0.4351\n",
      "Epoch 00090 | Loss: 0.4357\n",
      "Epoch 00091 | Loss: 0.4354\n",
      "F1-Score: 0.6178\n",
      "Epoch 00092 | Loss: 0.4351\n",
      "Epoch 00093 | Loss: 0.4355\n",
      "Epoch 00094 | Loss: 0.4346\n",
      "Epoch 00095 | Loss: 0.4333\n",
      "Epoch 00096 | Loss: 0.4328\n",
      "F1-Score: 0.6120\n",
      "Epoch 00097 | Loss: 0.4333\n",
      "Epoch 00098 | Loss: 0.4333\n",
      "Epoch 00099 | Loss: 0.4341\n",
      "Epoch 00100 | Loss: 0.4371\n",
      "Epoch 00101 | Loss: 0.4388\n",
      "F1-Score: 0.5832\n",
      "Epoch 00102 | Loss: 0.4421\n",
      "Epoch 00103 | Loss: 0.4368\n",
      "Epoch 00104 | Loss: 0.4338\n",
      "Epoch 00105 | Loss: 0.4334\n",
      "Epoch 00106 | Loss: 0.4309\n",
      "F1-Score: 0.5763\n",
      "Epoch 00107 | Loss: 0.4308\n",
      "Epoch 00108 | Loss: 0.4316\n",
      "Epoch 00109 | Loss: 0.4335\n",
      "Epoch 00110 | Loss: 0.4316\n",
      "Epoch 00111 | Loss: 0.4297\n",
      "F1-Score: 0.6185\n",
      "Epoch 00112 | Loss: 0.4267\n",
      "Epoch 00113 | Loss: 0.4255\n",
      "Epoch 00114 | Loss: 0.4251\n",
      "Epoch 00115 | Loss: 0.4256\n",
      "Epoch 00116 | Loss: 0.4271\n",
      "F1-Score: 0.5892\n",
      "Epoch 00117 | Loss: 0.4266\n",
      "Epoch 00118 | Loss: 0.4266\n",
      "Epoch 00119 | Loss: 0.4283\n",
      "Epoch 00120 | Loss: 0.4297\n",
      "Epoch 00121 | Loss: 0.4305\n",
      "F1-Score: 0.6307\n",
      "Epoch 00122 | Loss: 0.4310\n",
      "Epoch 00123 | Loss: 0.4271\n",
      "Epoch 00124 | Loss: 0.4253\n",
      "Epoch 00125 | Loss: 0.4263\n",
      "Epoch 00126 | Loss: 0.4250\n",
      "F1-Score: 0.5833\n",
      "Epoch 00127 | Loss: 0.4231\n",
      "Epoch 00128 | Loss: 0.4225\n",
      "Epoch 00129 | Loss: 0.4248\n",
      "Epoch 00130 | Loss: 0.4242\n",
      "Epoch 00131 | Loss: 0.4210\n",
      "F1-Score: 0.6220\n",
      "Epoch 00132 | Loss: 0.4221\n",
      "Epoch 00133 | Loss: 0.4208\n",
      "Epoch 00134 | Loss: 0.4194\n",
      "Epoch 00135 | Loss: 0.4217\n",
      "Epoch 00136 | Loss: 0.4207\n",
      "F1-Score: 0.6367\n",
      "Epoch 00137 | Loss: 0.4201\n",
      "Epoch 00138 | Loss: 0.4182\n",
      "Epoch 00139 | Loss: 0.4180\n",
      "Epoch 00140 | Loss: 0.4154\n",
      "Epoch 00141 | Loss: 0.4139\n",
      "F1-Score: 0.6116\n",
      "Epoch 00142 | Loss: 0.4130\n",
      "Epoch 00143 | Loss: 0.4131\n",
      "Epoch 00144 | Loss: 0.4132\n",
      "Epoch 00145 | Loss: 0.4129\n",
      "Epoch 00146 | Loss: 0.4123\n",
      "F1-Score: 0.6372\n",
      "Epoch 00147 | Loss: 0.4134\n",
      "Epoch 00148 | Loss: 0.4158\n",
      "Epoch 00149 | Loss: 0.4173\n",
      "Epoch 00150 | Loss: 0.4179\n",
      "Epoch 00151 | Loss: 0.4194\n",
      "F1-Score: 0.6335\n",
      "Epoch 00152 | Loss: 0.4205\n",
      "Epoch 00153 | Loss: 0.4201\n",
      "Epoch 00154 | Loss: 0.4194\n",
      "Epoch 00155 | Loss: 0.4205\n",
      "Epoch 00156 | Loss: 0.4194\n",
      "F1-Score: 0.6171\n",
      "Epoch 00157 | Loss: 0.4168\n",
      "Epoch 00158 | Loss: 0.4150\n",
      "Epoch 00159 | Loss: 0.4143\n",
      "Epoch 00160 | Loss: 0.4128\n",
      "Epoch 00161 | Loss: 0.4105\n",
      "F1-Score: 0.6411\n",
      "Epoch 00162 | Loss: 0.4091\n",
      "Epoch 00163 | Loss: 0.4087\n",
      "Epoch 00164 | Loss: 0.4082\n",
      "Epoch 00165 | Loss: 0.4072\n",
      "Epoch 00166 | Loss: 0.4080\n",
      "F1-Score: 0.6396\n",
      "Epoch 00167 | Loss: 0.4084\n",
      "Epoch 00168 | Loss: 0.4086\n",
      "Epoch 00169 | Loss: 0.4087\n",
      "Epoch 00170 | Loss: 0.4097\n",
      "Epoch 00171 | Loss: 0.4121\n",
      "F1-Score: 0.6114\n",
      "Epoch 00172 | Loss: 0.4111\n",
      "Epoch 00173 | Loss: 0.4103\n",
      "Epoch 00174 | Loss: 0.4100\n",
      "Epoch 00175 | Loss: 0.4108\n",
      "Epoch 00176 | Loss: 0.4103\n",
      "F1-Score: 0.6483\n",
      "Epoch 00177 | Loss: 0.4089\n",
      "Epoch 00178 | Loss: 0.4080\n",
      "Epoch 00179 | Loss: 0.4094\n",
      "Epoch 00180 | Loss: 0.4086\n",
      "Epoch 00181 | Loss: 0.4080\n",
      "F1-Score: 0.6159\n",
      "Epoch 00182 | Loss: 0.4076\n",
      "Epoch 00183 | Loss: 0.4066\n",
      "Epoch 00184 | Loss: 0.4072\n",
      "Epoch 00185 | Loss: 0.4060\n",
      "Epoch 00186 | Loss: 0.4092\n",
      "F1-Score: 0.6146\n",
      "Epoch 00187 | Loss: 0.4093\n",
      "Epoch 00188 | Loss: 0.4068\n",
      "Epoch 00189 | Loss: 0.4064\n",
      "Epoch 00190 | Loss: 0.4058\n",
      "Epoch 00191 | Loss: 0.4049\n",
      "F1-Score: 0.6519\n",
      "Epoch 00192 | Loss: 0.4030\n",
      "Epoch 00193 | Loss: 0.4036\n",
      "Epoch 00194 | Loss: 0.4047\n",
      "Epoch 00195 | Loss: 0.4032\n",
      "Epoch 00196 | Loss: 0.4052\n",
      "F1-Score: 0.6530\n",
      "Epoch 00197 | Loss: 0.4042\n",
      "Epoch 00198 | Loss: 0.4032\n",
      "Epoch 00199 | Loss: 0.4033\n",
      "Epoch 00200 | Loss: 0.4036\n"
     ]
    }
   ],
   "source": [
    "### DEVICE GPU OR CPU : will select GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"\\nDevice: \", device)\n",
    "\n",
    "### Max number of epochs\n",
    "max_epochs = 200\n",
    "\n",
    "### DEFINE THE MODEL\n",
    "basic_model = BasicGraphModel(  input_size = n_features, \n",
    "                                hidden_size = 256, \n",
    "                                output_size = n_classes).to(device)\n",
    "\n",
    "### DEFINE LOSS FUNCTION\n",
    "loss_fcn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "### DEFINE OPTIMIZER\n",
    "optimizer = torch.optim.Adam(basic_model.parameters(), lr=0.005)\n",
    "\n",
    "### TRAIN THE MODEL\n",
    "epoch_list, basic_model_scores = train(basic_model, loss_fcn, device, optimizer, max_epochs, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sGc5g7Xmap2"
   },
   "source": [
    "Let's evaluate the performance of this basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "ztfbbg2TNP7F",
    "outputId": "19fa3720-5b85-40da-8e24-3df54e5a0588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Model : F1-Score on the test set: 0.6350\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### F1-SCORE ON TEST DATASET\n",
    "score_test = evaluate(basic_model, loss_fcn, device, test_dataloader)\n",
    "print(\"Basic Model : F1-Score on the test set: {:.4f}\".format(score_test))\n",
    "\n",
    "### PLOT EVOLUTION OF F1-SCORE W.R.T EPOCHS\n",
    "def plot_f1_score(epoch_list, scores) :\n",
    "    plt.figure(figsize=[10,5])\n",
    "    plt.plot(epoch_list, scores)\n",
    "    plt.title(\"Evolution of F1S-Score w.r.t epochs\")\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.show()\n",
    "    \n",
    "plot_f1_score(epoch_list, basic_model_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRVsy5vLnWm_"
   },
   "source": [
    "### Define a better model\n",
    "\n",
    "Now, it's your turn to improve this basic model ! To do so, complete whenever ###### YOUR ANSWER ######## and run the two following cells.\n",
    "\n",
    "**HINT :** https://arxiv.org/pdf/1710.10903.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qTo7PxFpRHzL"
   },
   "outputs": [],
   "source": [
    "class StudentModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers = 3, num_heads = 2):\n",
    "          super().__init__()\n",
    "\n",
    "          self.pipeline = [graphnn.GATv2Conv(in_channels = input_size, out_channels = hidden_size, heads = num_heads)]\n",
    "\n",
    "          for _ in range(num_layers - 1):\n",
    "            layer = graphnn.GATv2Conv(in_channels = hidden_size * num_heads, out_channels = hidden_size, heads = num_heads)\n",
    "            self.pipeline.append(layer)         \n",
    "\n",
    "          #self.pipeline.append(nn.LeakyReLU(negative_slope = 0.2))\n",
    "          self.pipeline.append(graphnn.Linear(in_channels = hidden_size * num_heads, out_channels = output_size))\n",
    "          \n",
    "          self.pipeline = nn.Sequential(*self.pipeline)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "          for layer in self.pipeline[:-2]:\n",
    "            x = layer(x, edge_index)\n",
    "\n",
    "          #output = self.pipeline[-2](x)\n",
    "          output = self.pipeline[-1](x)\n",
    "\n",
    "          return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yGdQ2uxpCAX"
   },
   "source": [
    "Let's train your model !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XIYzkYRo3AQ",
    "outputId": "613ad4fd-9d34-4600-b680-6cc665939f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00001 | Loss: 0.6610\n",
      "F1-Score: 0.3711\n",
      "Epoch 00002 | Loss: 0.5516\n",
      "Epoch 00003 | Loss: 0.5285\n",
      "Epoch 00004 | Loss: 0.5161\n",
      "Epoch 00005 | Loss: 0.4933\n",
      "Epoch 00006 | Loss: 0.4749\n",
      "F1-Score: 0.5403\n",
      "Epoch 00007 | Loss: 0.4652\n",
      "Epoch 00008 | Loss: 0.4393\n",
      "Epoch 00009 | Loss: 0.4166\n",
      "Epoch 00010 | Loss: 0.4033\n",
      "Epoch 00011 | Loss: 0.3921\n",
      "F1-Score: 0.6685\n",
      "Epoch 00012 | Loss: 0.3651\n",
      "Epoch 00013 | Loss: 0.3493\n",
      "Epoch 00014 | Loss: 0.3757\n",
      "Epoch 00015 | Loss: 0.3416\n",
      "Epoch 00016 | Loss: 0.3168\n",
      "F1-Score: 0.7530\n",
      "Epoch 00017 | Loss: 0.3032\n",
      "Epoch 00018 | Loss: 0.2898\n",
      "Epoch 00019 | Loss: 0.2750\n",
      "Epoch 00020 | Loss: 0.2688\n",
      "Epoch 00021 | Loss: 0.2585\n",
      "F1-Score: 0.7964\n",
      "Epoch 00022 | Loss: 0.2471\n",
      "Epoch 00023 | Loss: 0.2366\n",
      "Epoch 00024 | Loss: 0.2228\n",
      "Epoch 00025 | Loss: 0.2114\n",
      "Epoch 00026 | Loss: 0.2049\n",
      "F1-Score: 0.8410\n",
      "Epoch 00027 | Loss: 0.2088\n",
      "Epoch 00028 | Loss: 0.2081\n",
      "Epoch 00029 | Loss: 0.2017\n",
      "Epoch 00030 | Loss: 0.1861\n",
      "Epoch 00031 | Loss: 0.1822\n",
      "F1-Score: 0.8622\n",
      "Epoch 00032 | Loss: 0.1727\n",
      "Epoch 00033 | Loss: 0.1705\n",
      "Epoch 00034 | Loss: 0.1711\n",
      "Epoch 00035 | Loss: 0.1646\n",
      "Epoch 00036 | Loss: 0.1544\n",
      "F1-Score: 0.8801\n",
      "Epoch 00037 | Loss: 0.1483\n",
      "Epoch 00038 | Loss: 0.1452\n",
      "Epoch 00039 | Loss: 0.1439\n",
      "Epoch 00040 | Loss: 0.1420\n",
      "Epoch 00041 | Loss: 0.1444\n",
      "F1-Score: 0.8848\n",
      "Epoch 00042 | Loss: 0.1470\n",
      "Epoch 00043 | Loss: 0.1446\n",
      "Epoch 00044 | Loss: 0.1424\n",
      "Epoch 00045 | Loss: 0.1320\n",
      "Epoch 00046 | Loss: 0.1260\n",
      "F1-Score: 0.8981\n",
      "Epoch 00047 | Loss: 0.1222\n",
      "Epoch 00048 | Loss: 0.1287\n",
      "Epoch 00049 | Loss: 0.1292\n",
      "Epoch 00050 | Loss: 0.1343\n",
      "Epoch 00051 | Loss: 0.1305\n",
      "F1-Score: 0.8997\n",
      "Epoch 00052 | Loss: 0.1316\n",
      "Epoch 00053 | Loss: 0.1275\n",
      "Epoch 00054 | Loss: 0.1237\n",
      "Epoch 00055 | Loss: 0.1174\n",
      "Epoch 00056 | Loss: 0.1295\n",
      "F1-Score: 0.8774\n",
      "Epoch 00057 | Loss: 0.1341\n",
      "Epoch 00058 | Loss: 0.1201\n",
      "Epoch 00059 | Loss: 0.1107\n",
      "Epoch 00060 | Loss: 0.1056\n",
      "Epoch 00061 | Loss: 0.1010\n",
      "F1-Score: 0.9138\n",
      "Epoch 00062 | Loss: 0.1001\n",
      "Epoch 00063 | Loss: 0.1009\n",
      "Epoch 00064 | Loss: 0.1014\n",
      "Epoch 00065 | Loss: 0.1019\n",
      "Epoch 00066 | Loss: 0.1037\n",
      "F1-Score: 0.9149\n",
      "Epoch 00067 | Loss: 0.1000\n",
      "Epoch 00068 | Loss: 0.0968\n",
      "Epoch 00069 | Loss: 0.0916\n",
      "Epoch 00070 | Loss: 0.0871\n",
      "Epoch 00071 | Loss: 0.0838\n",
      "F1-Score: 0.9287\n",
      "Epoch 00072 | Loss: 0.0825\n",
      "Epoch 00073 | Loss: 0.0819\n",
      "Epoch 00074 | Loss: 0.0856\n",
      "Epoch 00075 | Loss: 0.0899\n",
      "Epoch 00076 | Loss: 0.0916\n",
      "F1-Score: 0.9204\n",
      "Epoch 00077 | Loss: 0.0902\n",
      "Epoch 00078 | Loss: 0.0897\n",
      "Epoch 00079 | Loss: 0.0863\n",
      "Epoch 00080 | Loss: 0.0942\n",
      "Epoch 00081 | Loss: 0.0949\n",
      "F1-Score: 0.9220\n",
      "Epoch 00082 | Loss: 0.0935\n",
      "Epoch 00083 | Loss: 0.0874\n",
      "Epoch 00084 | Loss: 0.0821\n",
      "Epoch 00085 | Loss: 0.0795\n",
      "Epoch 00086 | Loss: 0.0770\n",
      "F1-Score: 0.9311\n",
      "Epoch 00087 | Loss: 0.0742\n",
      "Epoch 00088 | Loss: 0.0731\n",
      "Epoch 00089 | Loss: 0.0740\n",
      "Epoch 00090 | Loss: 0.0765\n",
      "Epoch 00091 | Loss: 0.0768\n",
      "F1-Score: 0.9303\n",
      "Epoch 00092 | Loss: 0.0783\n",
      "Epoch 00093 | Loss: 0.0780\n",
      "Epoch 00094 | Loss: 0.0829\n",
      "Epoch 00095 | Loss: 0.0837\n",
      "Epoch 00096 | Loss: 0.0793\n",
      "F1-Score: 0.9334\n",
      "Epoch 00097 | Loss: 0.0739\n",
      "Epoch 00098 | Loss: 0.0708\n",
      "Epoch 00099 | Loss: 0.0728\n",
      "Epoch 00100 | Loss: 0.0717\n",
      "Epoch 00101 | Loss: 0.0738\n",
      "F1-Score: 0.9339\n",
      "Epoch 00102 | Loss: 0.0710\n",
      "Epoch 00103 | Loss: 0.0738\n",
      "Epoch 00104 | Loss: 0.0740\n",
      "Epoch 00105 | Loss: 0.0747\n",
      "Epoch 00106 | Loss: 0.0734\n",
      "F1-Score: 0.9342\n",
      "Epoch 00107 | Loss: 0.0712\n",
      "Epoch 00108 | Loss: 0.0680\n",
      "Epoch 00109 | Loss: 0.0654\n",
      "Epoch 00110 | Loss: 0.0624\n",
      "Epoch 00111 | Loss: 0.0627\n",
      "F1-Score: 0.9418\n",
      "Epoch 00112 | Loss: 0.0622\n",
      "Epoch 00113 | Loss: 0.0646\n",
      "Epoch 00114 | Loss: 0.0723\n",
      "Epoch 00115 | Loss: 0.0768\n",
      "Epoch 00116 | Loss: 0.0762\n",
      "F1-Score: 0.9312\n",
      "Epoch 00117 | Loss: 0.0780\n",
      "Epoch 00118 | Loss: 0.0735\n",
      "Epoch 00119 | Loss: 0.0716\n",
      "Epoch 00120 | Loss: 0.0665\n",
      "Epoch 00121 | Loss: 0.0629\n",
      "F1-Score: 0.9426\n",
      "Epoch 00122 | Loss: 0.0605\n",
      "Epoch 00123 | Loss: 0.0579\n",
      "Epoch 00124 | Loss: 0.0585\n",
      "Epoch 00125 | Loss: 0.0611\n",
      "Epoch 00126 | Loss: 0.0626\n",
      "F1-Score: 0.9420\n",
      "Epoch 00127 | Loss: 0.0682\n",
      "Epoch 00128 | Loss: 0.0777\n",
      "Epoch 00129 | Loss: 0.1010\n",
      "Epoch 00130 | Loss: 0.1031\n",
      "Epoch 00131 | Loss: 0.0891\n",
      "F1-Score: 0.9327\n",
      "Epoch 00132 | Loss: 0.0765\n",
      "Epoch 00133 | Loss: 0.0681\n",
      "Epoch 00134 | Loss: 0.0634\n",
      "Epoch 00135 | Loss: 0.0611\n",
      "Epoch 00136 | Loss: 0.0596\n",
      "F1-Score: 0.9454\n",
      "Epoch 00137 | Loss: 0.0591\n",
      "Epoch 00138 | Loss: 0.0603\n",
      "Epoch 00139 | Loss: 0.0643\n",
      "Epoch 00140 | Loss: 0.0652\n",
      "Epoch 00141 | Loss: 0.0653\n",
      "F1-Score: 0.9427\n",
      "Epoch 00142 | Loss: 0.0610\n",
      "Epoch 00143 | Loss: 0.0624\n",
      "Epoch 00144 | Loss: 0.0597\n",
      "Epoch 00145 | Loss: 0.0606\n",
      "Epoch 00146 | Loss: 0.0616\n",
      "F1-Score: 0.9450\n",
      "Epoch 00147 | Loss: 0.0612\n",
      "Epoch 00148 | Loss: 0.0613\n",
      "Epoch 00149 | Loss: 0.0622\n",
      "Epoch 00150 | Loss: 0.0603\n",
      "Epoch 00151 | Loss: 0.0590\n",
      "F1-Score: 0.9454\n",
      "Epoch 00152 | Loss: 0.0581\n",
      "Epoch 00153 | Loss: 0.0563\n",
      "Epoch 00154 | Loss: 0.0546\n",
      "Epoch 00155 | Loss: 0.0544\n",
      "Epoch 00156 | Loss: 0.0542\n",
      "F1-Score: 0.9487\n",
      "Epoch 00157 | Loss: 0.0548\n",
      "Epoch 00158 | Loss: 0.0548\n",
      "Epoch 00159 | Loss: 0.0555\n",
      "Epoch 00160 | Loss: 0.0567\n",
      "Epoch 00161 | Loss: 0.0589\n",
      "F1-Score: 0.9435\n",
      "Epoch 00162 | Loss: 0.0603\n",
      "Epoch 00163 | Loss: 0.0586\n",
      "Epoch 00164 | Loss: 0.0574\n",
      "Epoch 00165 | Loss: 0.0549\n",
      "Epoch 00166 | Loss: 0.0541\n",
      "F1-Score: 0.9486\n",
      "Epoch 00167 | Loss: 0.0530\n",
      "Epoch 00168 | Loss: 0.0545\n",
      "Epoch 00169 | Loss: 0.0586\n",
      "Epoch 00170 | Loss: 0.0622\n",
      "Epoch 00171 | Loss: 0.0645\n",
      "F1-Score: 0.9436\n",
      "Epoch 00172 | Loss: 0.0650\n",
      "Epoch 00173 | Loss: 0.0618\n",
      "Epoch 00174 | Loss: 0.0558\n",
      "Epoch 00175 | Loss: 0.0550\n",
      "Epoch 00176 | Loss: 0.0520\n",
      "F1-Score: 0.9498\n",
      "Epoch 00177 | Loss: 0.0510\n",
      "Epoch 00178 | Loss: 0.0516\n",
      "Epoch 00179 | Loss: 0.0517\n",
      "Epoch 00180 | Loss: 0.0539\n",
      "Epoch 00181 | Loss: 0.0581\n",
      "F1-Score: 0.9436\n",
      "Epoch 00182 | Loss: 0.0580\n",
      "Epoch 00183 | Loss: 0.0571\n",
      "Epoch 00184 | Loss: 0.0546\n",
      "Epoch 00185 | Loss: 0.0525\n",
      "Epoch 00186 | Loss: 0.0499\n",
      "F1-Score: 0.9522\n",
      "Epoch 00187 | Loss: 0.0493\n",
      "Epoch 00188 | Loss: 0.0518\n",
      "Epoch 00189 | Loss: 0.0540\n",
      "Epoch 00190 | Loss: 0.0559\n",
      "Epoch 00191 | Loss: 0.0595\n",
      "F1-Score: 0.9402\n",
      "Epoch 00192 | Loss: 0.0616\n",
      "Epoch 00193 | Loss: 0.0593\n",
      "Epoch 00194 | Loss: 0.0573\n",
      "Epoch 00195 | Loss: 0.0564\n",
      "Epoch 00196 | Loss: 0.0572\n",
      "F1-Score: 0.9487\n",
      "Epoch 00197 | Loss: 0.0565\n",
      "Epoch 00198 | Loss: 0.0587\n",
      "Epoch 00199 | Loss: 0.0572\n",
      "Epoch 00200 | Loss: 0.0541\n"
     ]
    }
   ],
   "source": [
    "## Student model\n",
    "student_model = StudentModel(input_size = n_features, \n",
    "                                hidden_size = 256, \n",
    "                                output_size = n_classes, num_layers = 3, num_heads = 4).to(device)\n",
    "\n",
    "### DEFINE LOSS FUNCTION AND OPTIMIZER\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=0.005)\n",
    "\n",
    "### TRAIN\n",
    "epoch_list, student_model_scores = train(student_model, loss_fcn, device, optimizer, max_epochs, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWatNTPBpQGY"
   },
   "source": [
    "Let's evaluate the performance of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "WFWMqwDuSj7b",
    "outputId": "7ca58fc6-eaf8-4f9e-f29b-66c636771ba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model : F1-Score on the test set: 0.9663\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_test = evaluate(student_model, loss_fcn, device, test_dataloader)\n",
    "print(\"Student Model : F1-Score on the test set: {:.4f}\".format(score_test))\n",
    "\n",
    "def plot_f1_score(epoch_list, basic_model_scores, student_model_scores) :\n",
    "    plt.figure(figsize = [10,5])\n",
    "    plt.plot(epoch_list, basic_model_scores, 'b', label = \"Basic Model\")\n",
    "    plt.plot(epoch_list, student_model_scores, 'r', label = \"Student Model\")\n",
    "    plt.title(\"Evolution of f1 score w.r.t epochs\")\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"F1-Score\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_f1_score(epoch_list, basic_model_scores, student_model_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9aVEYkuR3fp"
   },
   "source": [
    "## **PART 2 : QUESTIONS** (12/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZ-r6AWtR-Co"
   },
   "source": [
    "**1. Make a small paragraph that : (4pts)**\n",
    "1. Explains your achitecture and justify your choices (why the Graph Layer you chose is more efficient than the GCNLayer from the Basic Model?).\n",
    "2. Analyses your results (what is the F1-Score ? are your results convincing ? what is your position w.r.t state-of-the-art ?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aiCvW4q5jRY"
   },
   "source": [
    "**1. Answer :**\n",
    "\n",
    "1. The model we having the best performances among those we tried to implement is deeply inspired by the GAT algorithm, which is described in the paper given as hint for the exercise. It consists in 3 successive GATv2Layer, which are basically an evolution correcting the static attention problem of the initial GATLayer, the attention layer described in the pre-cited article. Then the results (having the size equals to the multiplication of the hidden_size and num_heads parameters) are sent into a LeakyReLU layer and finally to a Linear layer, which is used for the final categorization of each input in the correct number of categories. We conducted a finetuning of the parameters of this model in order to define : the number of successive GATv2Layers and the number of heads to use as our model can work through the multi-head attention process. We found that the best results were found for a number of successive attention layers equals to 3 and a number of heads equals to 2.  \n",
    "The use of GATLayers (Attention layers) instead of GraphConv Layers is justified for many reaseons :\n",
    "  - Contrary to GraphConv Layers, a model with attention layers does not require to have an undirected graph. This is implied by the fact that there is no more an impact of the order of access to the graph. \n",
    "  - This model is said to be a lot more efficient, particularly because all steps of it can be parallelized across all edges.\n",
    "  - Contrary to the GraphConv model, GAT can be used in parallel with the multi-head attention mechanism, which can also increase the efficiency of our model. \n",
    "\n",
    "2. We obtained a final F1-Score equals to 0.9784 on the last run (between 0.95 and 0.98 according to the tries). This result is very good, particularly when compared to the Basic Model constructed with GCNLayer whose result is generally not far from 0.6.  \n",
    "We can compare this result with the state-of-the-art architectures proposed in the previous paper. According to it, the best model (at that time in 2018) was their GAT model (using the basic GATLayer of the torchnn package) with a benchmarked F1-score of 0.973. The model we were able to build is therefore slightly better than the 2018-top-of-the-art models. That can be explained by the similarities between the two models and also by the fact that we are using an upgraded version of the GATLayers\n",
    "Moreover, after the 200 epochs of the training process, the loss obtained with our model lies between 0.05 and 0.06, which is 10 times less than the initial loss. We see clearly that our model converges to a good solution, and therefore we may say that our results are satisfying.  \n",
    "Finally, the model we built converges also in a really short time compared to the Basic one. Indeed, after 50 epochs, the F1-score is already above 0.9 in the first case, whereas we can not identify any convergence in the second one, which seems not to have converged even after 200 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HIVqG4u5jfc"
   },
   "source": [
    "**2. Provide a diagramm of your architecture, which includes a good and clear legend as well as shapes information. The diagramm must be submitted as an external file, along with this notebook (PDF, JEPG or PNG format accepted). (2pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crMHLjkJ5pxl"
   },
   "source": [
    "**3. Make a small paragraph that explains: (6pts)**\n",
    "1. What _oversmoothing_ is in the context of Graph Neural Network. Why is it an issue ? \n",
    "2. Are there solutions to overcome it ? \n",
    "3. Do you think the model you constructed is robust with respect to oversmoothing ? Why ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLPosSov_uPK"
   },
   "source": [
    "**3. Answer :**\n",
    "\n",
    "1. Oversmoothing is a phenomenon occuring when information propagation across the graph is too strong, resulting in nodes becoming too similar in their representation. This problem mainly occurs when the network is built with too many layers, each of them being too heavily weighted. As a result, during calculations, all the nodes in the graph will lose their own caracteristics (being \"diluted\" by all the neighbouring edges) and will therefore become indistinguishable one from one another : this is explaining where the \"smoothing\" part of the name comes from.\n",
    "To conclude, oversmoothing often leads to bad (or at least worse) performances, because, with such undistinguability between nodes, the model can not work properly.\n",
    "\n",
    "2. There are several tehcniques to overcome oversmoothing, among which we can note :\n",
    "  * Using of dropout can also be used to solve it, because a random drop out of nodes during training will precisely prevent any overfitting and therefore oversmoothing by reducing the number of nodes considered in the neighbourhood of each one. \n",
    "  * Using skip connections between layers, which allow for direct information flow between layers and help to prevent the loss of node identity. \n",
    "  \n",
    "\n",
    "3. Our scheme is using the attention principle which is designed to be robust with respect to oversmoothing. Indeed, GAT uses a self-attention mechanism to weight the importance of neighboring nodes, and allows therefore the network to selectively aggregate information from neighbors based on their relevance to the target node, rather than blindly aggregating information from all neighboring nodes, which could have lead to oversmoothing as the nodes of the graph are already well-connected one to each other.  \n",
    "Finally, as explained before, oversmoothing accurs when too many layers are used in the model. In our case, the architecture of our model consists in only 4 layers (3 GATv2Conv layers and 1 Linear one), and therefore can not be considered as really deep. Therefore, even though we did not used any Dropout (which could once again reduce the risk of oversmoothing), the risk of it remains quite low."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "v5Lp4PasOby4"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
